{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc0acbb7",
   "metadata": {},
   "source": [
    "# Genome Assembly with Canu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0a98a",
   "metadata": {},
   "source": [
    "[Canu](https://canu.readthedocs.io/en/latest/quick-start.html) \"specializes in assembling PacBio or Oxford Nanopore sequences. Canu operates in three phases: correction, trimming and assembly. The correction phase will improve the accuracy of bases in reads. The trimming phase will trim reads to the portion that appears to be high-quality sequence, removing suspicious regions such as remaining SMRTbell adapter. The assembly phase will order the reads into contigs, generate consensus sequences and create graphs of alternate paths.\n",
    "\n",
    "For eukaryotic genomes, coverage more than 20x is enough to outperform current hybrid methods, however, between 30x and 60x coverage is the recommended minimum. More coverage will let Canu use longer reads for assembly, which will result in better assemblies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff30a07",
   "metadata": {},
   "source": [
    "## What you'll need to run this notebook\n",
    "\n",
    "1. You will need a set of sequencing reads produced previously (i.e. from running your `ReadQC-with-fastp` notebook). \n",
    "2. We recommend running this notebook with at least 32 CPUs and 64GB of RAM - genome assembly is usually computationally intensive. Some programs may take days even on a very powerful machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b372d34",
   "metadata": {},
   "source": [
    "### Watch the video introduction for a little bit of background on how this assembly tool works\n",
    "\n",
    "[Canu: Long Read Genome Assembly Tool](https://youtu.be/rb9w9y9e9gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df5c52",
   "metadata": {},
   "source": [
    "## Installing Canu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c8282",
   "metadata": {},
   "source": [
    "As always, we will install the software; again we will use conda. \n",
    "\n",
    "**Important**: Make sure you execute each numbered step "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc861f3",
   "metadata": {},
   "source": [
    "1. We will search for the tool we want to install\n",
    "\n",
    "We will use the `conda search` command and the channel (`-c`) flag to search [bioconda](https://bioconda.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda search canu -c bioconda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba404d",
   "metadata": {},
   "source": [
    "2. Create a conda enviornment\n",
    "\n",
    "Conda uses something called \"enviornments\" which are essentially isolated configurations on our computer where we can included all the needed compatible tools and exlude other tools which are unnesessary or would have conflicts with our desired tool. We will use the `-y` option to install without prompting the user for input, the `--name` option to name the enviornment for the tool. We will enforce versioning (`tool==version`) so that we know what version of a tool was used to do an analysis should we wish to repeat the analysis. \n",
    "\n",
    "**Tip**: Use the latest version where possible, but if you get an error with dependancies, using a lower version may help. Some tools may never be installed successfully using conda, but we will face those when we have too. \n",
    "\n",
    "**Bonus tip**: In the installation command below we also specify the [build](https://medium.com/webgentle/what-is-the-software-build-all-you-need-to-know-4046b0e674bb) by adding an additional `=` after the version (2.5) and copying from the build column from our search results  above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba0bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -y --name canu canu==2.2=ha47f30e_0 -c bioconda -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5525a8af",
   "metadata": {},
   "source": [
    "3. We will use the `conda init` command so that conda can be configured for this shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0204d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32427a69",
   "metadata": {},
   "source": [
    "4. **DON'T SKIP**: We need to restart the computer's [kernal](https://en.wikipedia.org/wiki/Kernel_(operating_system)). Go to the **Kernal** menu and choose **Restart Kernal**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f50150",
   "metadata": {},
   "source": [
    "5. Finally, we can activate the conda enviornment (created with the name used for the environment). When you run the next cell it should return the name of the environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b257262",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate canu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00526125",
   "metadata": {},
   "source": [
    "## Running Canu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb5a542",
   "metadata": {},
   "source": [
    "Previously, we ran our assembly on a small subset of reads (100 or 1000 reads). Here we may as well run on the entire set of reads from your quality control step. \n",
    "\n",
    "**Tip**: When using commands or searching for files, the tab key will help you autocomplete (and help ensure the files and commands you think you have are actually accessible).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7bb63",
   "metadata": {},
   "source": [
    "## Questions to answer before running this software\n",
    "\n",
    "It's important you know these answers. You will likely do more than one assembly so that you can tweak the settings and make improvements. You may need to refer to your `fastp` output to answer these. \n",
    "\n",
    "1. What is the name of the file containing your cleaned reads\n",
    "2. How many reads total do you have in your input? \n",
    "3. How many nucleotides do you have in your input? \n",
    "4. What is the mean length of your reads?\n",
    "5. What percentage of reads are Q20 ([phred score](https://en.wikipedia.org/wiki/Phred_quality_score)) or above?\n",
    "6. What is your estimated coverage?\n",
    "\n",
    "To answer question #6 remember, coverage is how many nucleotides you have/the size (also in nucleotides) of the genome. For example, if you have 5 Gigabases (5GiB, 5,000,000,000 bases) and your genome is 150Mb, 150,000,000 you have ~ 33X coverage (33 times the genome size). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7a1f7-6de2-4841-a82e-480f749deb39",
   "metadata": {},
   "source": [
    "## Notes on Canu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96d04b-666e-40c8-a4a0-e658d59a6daf",
   "metadata": {},
   "source": [
    "Canu is a \"beast\" of a program, actually it is several programs for correction of reads, trimming, and construction of contigs. It can produce very nice assemblies, but it may take a long time (days - week+) and use a lot of resources \n",
    "\n",
    " >We don’t have a good way to estimate of disk space used for the assembly. It varies with genome size, repeat content, and sequencing depth. A human genome sequenced with PacBio or Nanopore at 40-50x typically requires 1-2TB of space at the peak. Plants, unfortunately, seem to want a lot of space. 10TB is a reasonable guess. We’ve seen it as bad as 20TB on some very repetitive genomes. ([Canu FAQ](https://canu.readthedocs.io/en/latest/faq.html)). \n",
    " \n",
    "From the [Canu documentation](https://canu.readthedocs.io/en/latest/quick-start.html) here are the steps Canu will undertake: \n",
    "\n",
    "\n",
    "- Load reads into the read database, gkpStore.\n",
    "- Compute k-mer counts in preparation for the overlap computation.\n",
    "- Compute overlaps.\n",
    "- Load overlaps into the overlap database, ovlStore.\n",
    "- Do something interesting with the reads and overlaps.\n",
    "  - The read correction task will replace the original noisy read sequences with consensus sequences computed from overlapping reads.\n",
    "   - The read trimming task will use overlapping reads to decide what regions of each read are high-quality sequence, and what regions should be trimmed. After trimming, the single largest high-quality chunk of sequence is retained.\n",
    "   - The unitig construction task finds sets of overlaps that are consistent, and uses those to place reads into a multialignment layout. The layout is then used to generate a consensus sequence for the unitig.\n",
    "\n",
    "**When running this program expect that it will take significant time. You may need to come back regularly to extend your time on VICE. You will get warnings by email from CyVerse as you approach your time limit. Go to analyses and select the running analysis for this notebook to extend the time.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab08414c",
   "metadata": {},
   "source": [
    "### Canu options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d325244",
   "metadata": {},
   "source": [
    "There are many more possibe `canu` options then we will play with. Here are the important ones for our exercises. You can see the whole list of options in the [canu parameter reference](https://canu.readthedocs.io/en/latest/parameter-reference.html). \n",
    "\n",
    "- `-p`: Specify a prefix name to label all files \n",
    "- `-d`: Specify a directory to output files\n",
    "- `genomeSize=<number>[g|m|k]`: A genome size estimate in billions (g), millions (m), or thousands (k). \n",
    "- `maxInputCoverage=<number>`: randomly down-sample input reads to this coverage\n",
    "- `-nanopore`: Optimizes settings for nanopore data\n",
    "\n",
    "The type of read (i.e. Nanopore) should be followed with the path to the reads to assemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdeb66",
   "metadata": {},
   "source": [
    "**Tip**: Use the help command to see all options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38452c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "canu --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7c4a44",
   "metadata": {},
   "source": [
    "### Example 1 (optional) - running canu on `spolyrhiza_reads_filtered.fastq.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e4d45",
   "metadata": {},
   "source": [
    "The file `spolyrhiza_reads_filtered.fastq.gz` was generated in advance using the raw reads (`spolyrhiza_reads.fastq.gz`) cleaned and flitered with `fastp`. The resulting data set has the following characteristics: \n",
    "\n",
    "- Total reads: 1.06 million\n",
    "- Total bases: 6.57 billion \n",
    "- Q20 bases: 4.39 billion\n",
    "- Mean read length: 6149bp\n",
    "\n",
    "If you like, you can run `canu` on this dataset (since we know it works and will generate an assembly). The following command is a good example to show you how to run `canu`. You can modify it to run with your own input file. \n",
    "\n",
    "**Tip**: The *S.polyrhiza* genome size is about 150 million bases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f6195",
   "metadata": {},
   "source": [
    "1. First, since we will have a lot of results, let's make an output directory first to keep results organizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p data/output/canu_example_assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d71bf66",
   "metadata": {},
   "source": [
    "2. Redbean has two steps to generate the assembly. First reads are assembled into a \"contig layout\" and another command is used to \"condense\" those contigs into the final consensus in FASTA. \n",
    "\n",
    "First we run the command below to assemble (this will take **several** hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270613f9",
   "metadata": {},
   "source": [
    "**IMPORTANT - how to know when this is finnished**: The [\\*] you see next to a cell indicates that a program is running. If you see this, the program is still running (even though a given stage of the program may say \"DONE\"). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- canu 2.2\n",
      "--\n",
      "-- CITATIONS\n",
      "--\n",
      "-- For 'standard' assemblies of PacBio or Nanopore reads:\n",
      "--   Koren S, Walenz BP, Berlin K, Miller JR, Phillippy AM.\n",
      "--   Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation.\n",
      "--   Genome Res. 2017 May;27(5):722-736.\n",
      "--   http://doi.org/10.1101/gr.215087.116\n",
      "-- \n",
      "-- Read and contig alignments during correction and consensus use:\n",
      "--   Šošic M, Šikic M.\n",
      "--   Edlib: a C/C ++ library for fast, exact sequence alignment using edit distance.\n",
      "--   Bioinformatics. 2017 May 1;33(9):1394-1395.\n",
      "--   http://doi.org/10.1093/bioinformatics/btw753\n",
      "-- \n",
      "-- Overlaps are generated using:\n",
      "--   Berlin K, et al.\n",
      "--   Assembling large genomes with single-molecule sequencing and locality-sensitive hashing.\n",
      "--   Nat Biotechnol. 2015 Jun;33(6):623-30.\n",
      "--   http://doi.org/10.1038/nbt.3238\n",
      "-- \n",
      "--   Myers EW, et al.\n",
      "--   A Whole-Genome Assembly of Drosophila.\n",
      "--   Science. 2000 Mar 24;287(5461):2196-204.\n",
      "--   http://doi.org/10.1126/science.287.5461.2196\n",
      "-- \n",
      "-- Corrected read consensus sequences are generated using an algorithm derived from FALCON-sense:\n",
      "--   Chin CS, et al.\n",
      "--   Phased diploid genome assembly with single-molecule real-time sequencing.\n",
      "--   Nat Methods. 2016 Dec;13(12):1050-1054.\n",
      "--   http://doi.org/10.1038/nmeth.4035\n",
      "-- \n",
      "-- Contig consensus sequences are generated using an algorithm derived from pbdagcon:\n",
      "--   Chin CS, et al.\n",
      "--   Nonhybrid, finished microbial genome assemblies from long-read SMRT sequencing data.\n",
      "--   Nat Methods. 2013 Jun;10(6):563-9\n",
      "--   http://doi.org/10.1038/nmeth.2474\n",
      "-- \n",
      "-- CONFIGURE CANU\n",
      "--\n",
      "-- Detected Java(TM) Runtime Environment '1.8.0_312' (from '/opt/anaconda3/envs/canu/bin/java') with -d64 support.\n",
      "--\n",
      "-- WARNING:\n",
      "-- WARNING:  Failed to run gnuplot using command 'gnuplot'.\n",
      "-- WARNING:  Plots will be disabled.\n",
      "-- WARNING:\n",
      "--\n",
      "--\n",
      "-- Detected 40 CPUs and 252 gigabytes of memory on the local machine.\n",
      "--\n",
      "-- Local machine mode enabled; grid support not detected or not allowed.\n",
      "--\n",
      "--                                (tag)Concurrency\n",
      "--                         (tag)Threads          |\n",
      "--                (tag)Memory         |          |\n",
      "--        (tag)             |         |          |       total usage      algorithm\n",
      "--        -------  ----------  --------   --------  --------------------  -----------------------------\n",
      "-- Local: meryl     24.000 GB    8 CPUs x   5 jobs   120.000 GB  40 CPUs  (k-mer counting)\n",
      "-- Local: hap       12.000 GB   20 CPUs x   2 jobs    24.000 GB  40 CPUs  (read-to-haplotype assignment)\n",
      "-- Local: cormhap   13.000 GB   10 CPUs x   4 jobs    52.000 GB  40 CPUs  (overlap detection with mhap)\n",
      "-- Local: obtovl     8.000 GB    8 CPUs x   5 jobs    40.000 GB  40 CPUs  (overlap detection)\n",
      "-- Local: utgovl     8.000 GB    8 CPUs x   5 jobs    40.000 GB  40 CPUs  (overlap detection)\n",
      "-- Local: cor        -.--- GB    4 CPUs x   - jobs     -.--- GB   - CPUs  (read correction)\n",
      "-- Local: ovb        4.000 GB    1 CPU  x  40 jobs   160.000 GB  40 CPUs  (overlap store bucketizer)\n",
      "-- Local: ovs        8.000 GB    1 CPU  x  31 jobs   248.000 GB  31 CPUs  (overlap store sorting)\n",
      "-- Local: red       16.000 GB    5 CPUs x   8 jobs   128.000 GB  40 CPUs  (read error detection)\n",
      "-- Local: oea        8.000 GB    1 CPU  x  31 jobs   248.000 GB  31 CPUs  (overlap error adjustment)\n",
      "-- Local: bat       64.000 GB    8 CPUs x   1 job     64.000 GB   8 CPUs  (contig construction with bogart)\n",
      "-- Local: cns        -.--- GB    8 CPUs x   - jobs     -.--- GB   - CPUs  (consensus)\n",
      "--\n",
      "-- Found untrimmed raw Nanopore reads in the input files.\n",
      "--\n",
      "-- Generating assembly 'example_spolyrhiza' in '/data/output/canu_example_assembly':\n",
      "--   genomeSize:\n",
      "--     150000000\n",
      "--\n",
      "--   Overlap Generation Limits:\n",
      "--     corOvlErrorRate 0.3200 ( 32.00%)\n",
      "--     obtOvlErrorRate 0.1200 ( 12.00%)\n",
      "--     utgOvlErrorRate 0.1200 ( 12.00%)\n",
      "--\n",
      "--   Overlap Processing Limits:\n",
      "--     corErrorRate    0.3000 ( 30.00%)\n",
      "--     obtErrorRate    0.1200 ( 12.00%)\n",
      "--     utgErrorRate    0.1200 ( 12.00%)\n",
      "--     cnsErrorRate    0.2000 ( 20.00%)\n",
      "--\n",
      "--   Stages to run:\n",
      "--     correct raw reads.\n",
      "--     trim corrected reads.\n",
      "--     assemble corrected and trimmed reads.\n",
      "--\n",
      "--\n",
      "-- BEGIN CORRECTION\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Mar 15 18:04:25 2022 with 0 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    ./example_spolyrhiza.seqStore.sh \\\n",
      "    > ./example_spolyrhiza.seqStore.err 2>&1\n"
     ]
    }
   ],
   "source": [
    "canu -p example_spolyrhiza \\\n",
    "     -d data/output/canu_example_assembly \\\n",
    "     genomeSize=150m \\\n",
    "     maxInputCoverage=100 \\\n",
    "     -nanopore \\\n",
    "     /data/input/concat_fastq/spolyrhiza_reads_filtered.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0a381",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Like most assemblers, at each step `canu` will generate several intermediate outputs. In the output folder, you will see several folders of results. The ultimate file will be called <YOUR-PREFIX>.contigs.fasta (`your-prefix` will be whatever you specified in the command you used to start canu. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb1027",
   "metadata": {},
   "source": [
    "## Challenge - Use Canu to assemble your reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ba959",
   "metadata": {},
   "source": [
    "Now, it's up to you to use  `canu` to generate your own genome assembly using the reads generated by fastp. \n",
    "\n",
    "\n",
    "### What to do\n",
    "\n",
    "1. Use the `mkdir` command to make a unique output directory to save your results (e.g. canu_assembly_1, canu_assembly_2). Make a new folder each time you do a new assembly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a342d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7ac79",
   "metadata": {},
   "source": [
    "2. Complete the command below to try an assembly using the same parameters as the example above. You will have to adjust the f prefix name (`-p`) something of your choice, specify the output directory (`-d`). Canus will atomatically use available CPU threads; CPU number was specified when you launched the application in the Discovery Environment. \n",
    "\n",
    "**Note about completing the cells below**\n",
    "- Enter your options after the flag (e.g. `-p`) and before the `\\`\n",
    "- Leave a space between what you write and the `\\`\n",
    "- Look closely how the working commands in the example are written if you have difficulties\n",
    "- Look closely for errors (unable to find file,  unable to write file, etc.)\n",
    "- Don't forget to end the command with the path to your reads. \n",
    "- Ask for help if you can't get something to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a36300",
   "metadata": {},
   "outputs": [],
   "source": [
    "canu -p  \\\n",
    "     -d  \\\n",
    "     genomeSize= \\\n",
    "     maxInputCoverage=100 \\\n",
    "     -nanopore \\\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365b630",
   "metadata": {},
   "source": [
    "3. Things to change. There are many things you can change which may improve (or worsen) the quality of your assembly. For now, it does not make sense to try too many things. Since canu does its own read correction, and interesting thing to try would be running it with unfiltered/uncorrected reads vs. reads you filtered with `fastp`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de604ed",
   "metadata": {},
   "source": [
    "## Try something\n",
    "\n",
    "Generate another assembly to see what parameters make a difference. \n",
    "\n",
    "Possible changes to try\n",
    "\n",
    "- You were asked to create two different `fastp` outputs, try them both with the same settings\n",
    "- Try canu on reads that were unfliltered by `fastp`. \n",
    "\n",
    "Add as many cells as you need to try alternative assembles. You should also try at least one other assembler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadd845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154e5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1b2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db14cb92",
   "metadata": {},
   "source": [
    "## Document your work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe60c6",
   "metadata": {},
   "source": [
    "We need to keep good track on what changes were made/how a file was produced so that we can fully document our work. In this exercise, it will be critical to know your settings so we can compare results across everyone who does this experiment. You will also be able to go back and reproduce your work if needed. \n",
    "\n",
    "**Make sure to save a copy of this notebook**\n",
    "\n",
    "When you terminate your application in CyVerse the results and data should be written back. You can also select this notebook in the file browser and choose Save and Export Notebook As (HTML) to save an easy-to-read version you can view anytime. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
